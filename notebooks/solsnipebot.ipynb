{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e52d274-790c-4ef6-ab41-126a155e0e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Solana Memecoin Sniping Bot\n",
    "Integrates Dexscreener API and Twitter trends for automated memecoin sniping\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "from typing import Optional, Dict, Any, List, Tuple\n",
    "import warnings\n",
    "import json\n",
    "import asyncio\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Suppress pandas warnings\n",
    "pd.options.mode.chained_assignment = None\n",
    "warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)\n",
    "\n",
    "# HTTP requests\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "# Solana blockchain libraries\n",
    "try:\n",
    "    from solders.keypair import Keypair\n",
    "    from solders.pubkey import Pubkey\n",
    "    from solders.rpc.responses import GetTransactionResp\n",
    "    from solders.transaction import Transaction\n",
    "    from solana.rpc.async_api import AsyncClient\n",
    "    from solana.rpc.commitment import Confirmed, Finalized\n",
    "    from solana.rpc.types import TxOpts\n",
    "    import base58\n",
    "    SOLANA_AVAILABLE = True\n",
    "except ImportError:\n",
    "    SOLANA_AVAILABLE = False\n",
    "    logging.warning(\"Solana libraries not available. Install: pip install solana solders\")\n",
    "\n",
    "# Jupiter DEX aggregator for swaps\n",
    "try:\n",
    "    import jupiter_python_sdk\n",
    "    JUPITER_AVAILABLE = True\n",
    "except ImportError:\n",
    "    JUPITER_AVAILABLE = False\n",
    "    logging.warning(\"Jupiter SDK not available. Install: pip install jupiter-python-sdk\")\n",
    "\n",
    "# Twitter/X API\n",
    "TWITTER_LIB = None\n",
    "try:\n",
    "    from twitter_api_v2 import TwitterApi\n",
    "    TWITTER_AVAILABLE = True\n",
    "    TWITTER_LIB = 'twitter_api_v2'\n",
    "except ImportError:\n",
    "    try:\n",
    "        import tweepy\n",
    "        TWITTER_AVAILABLE = True\n",
    "        TWITTER_LIB = 'tweepy'\n",
    "    except ImportError:\n",
    "        TWITTER_AVAILABLE = False\n",
    "        logging.warning(\"Twitter API libraries not available. Install: pip install tweepy or twitter-api-v2\")\n",
    "\n",
    "# Observability\n",
    "from prometheus_client import Counter, Gauge, Histogram, start_http_server\n",
    "import json\n",
    "\n",
    "# Database (TimescaleDB) - reuse from existing code\n",
    "try:\n",
    "    import psycopg2\n",
    "    from psycopg2.extras import execute_values\n",
    "    from psycopg2.pool import SimpleConnectionPool\n",
    "    DB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    DB_AVAILABLE = False\n",
    "\n",
    "# Configure logging\n",
    "def setup_logging(level=logging.INFO):\n",
    "    \"\"\"Setup logging\"\"\"\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(level)\n",
    "    logger.handlers.clear()\n",
    "    \n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    handler = logging.StreamHandler(sys.stdout)\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "    \n",
    "    return logger\n",
    "\n",
    "logger = setup_logging()\n",
    "\n",
    "# Prometheus metrics\n",
    "snipe_attempts = Counter('snipe_attempts_total', 'Total snipe attempts', ['status'])\n",
    "snipe_success = Counter('snipe_success_total', 'Successful snipes', ['token'])\n",
    "snipe_failures = Counter('snipe_failures_total', 'Failed snipes', ['reason'])\n",
    "active_positions = Gauge('active_positions', 'Number of active positions')\n",
    "token_score = Gauge('token_score', 'Token score for sniping', ['token_address'])\n",
    "twitter_mentions = Counter('twitter_mentions_total', 'Twitter mentions tracked', ['token'])\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TokenInfo:\n",
    "    \"\"\"Token information from Dexscreener\"\"\"\n",
    "    address: str\n",
    "    name: str\n",
    "    symbol: str\n",
    "    price_usd: float\n",
    "    price_change_24h: float\n",
    "    volume_24h: float\n",
    "    liquidity: float\n",
    "    fdv: float  # Fully diluted valuation\n",
    "    market_cap: float\n",
    "    pair_created_at: datetime\n",
    "    dex_id: str\n",
    "    chain_id: str\n",
    "    pair_address: str\n",
    "    score: float = 0.0  # Calculated score for sniping\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TwitterTrend:\n",
    "    \"\"\"Twitter trend information\"\"\"\n",
    "    token_address: str\n",
    "    mentions_count: int\n",
    "    engagement_rate: float\n",
    "    sentiment_score: float  # -1 to 1\n",
    "    trending_keywords: List[str]\n",
    "    last_updated: datetime\n",
    "\n",
    "\n",
    "class DexscreenerAPI:\n",
    "    \"\"\"Dexscreener API client for token discovery\"\"\"\n",
    "    \n",
    "    def __init__(self, base_url: str = \"https://api.dexscreener.com/latest/dex\"):\n",
    "        self.base_url = base_url\n",
    "        self.session = self._create_session()\n",
    "        self.rate_limit_delay = 0.5  # Delay between requests\n",
    "        \n",
    "    def _create_session(self):\n",
    "        \"\"\"Create requests session with retry strategy\"\"\"\n",
    "        session = requests.Session()\n",
    "        retry_strategy = Retry(\n",
    "            total=3,\n",
    "            backoff_factor=1,\n",
    "            status_forcelist=[429, 500, 502, 503, 504],\n",
    "        )\n",
    "        adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "        session.mount(\"http://\", adapter)\n",
    "        session.mount(\"https://\", adapter)\n",
    "        return session\n",
    "    \n",
    "    def get_tokens_by_chain(self, chain: str = \"solana\", limit: int = 100) -> List[Dict]:\n",
    "        \"\"\"Get trending tokens on a specific chain\"\"\"\n",
    "        try:\n",
    "            time.sleep(self.rate_limit_delay)\n",
    "            url = f\"{self.base_url}/tokens/{chain}\"\n",
    "            response = self.session.get(url, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            if 'pairs' in data:\n",
    "                return data['pairs'][:limit]\n",
    "            return []\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error fetching tokens from Dexscreener: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def get_token_info(self, token_address: str, chain: str = \"solana\") -> Optional[Dict]:\n",
    "        \"\"\"Get detailed information about a specific token\"\"\"\n",
    "        try:\n",
    "            time.sleep(self.rate_limit_delay)\n",
    "            url = f\"{self.base_url}/tokens/{token_address}\"\n",
    "            response = self.session.get(url, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            if 'pairs' in data and len(data['pairs']) > 0:\n",
    "                return data['pairs'][0]\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error fetching token info for {token_address}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def search_tokens(self, query: str, chain: str = \"solana\") -> List[Dict]:\n",
    "        \"\"\"Search for tokens by name or symbol\"\"\"\n",
    "        try:\n",
    "            time.sleep(self.rate_limit_delay)\n",
    "            url = f\"{self.base_url}/search\"\n",
    "            params = {\"q\": query}\n",
    "            response = self.session.get(url, params=params, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            if 'pairs' in data:\n",
    "                # Filter by chain\n",
    "                return [pair for pair in data['pairs'] if pair.get('chainId') == chain]\n",
    "            return []\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error searching tokens: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def parse_token_info(self, pair_data: Dict) -> Optional[TokenInfo]:\n",
    "        \"\"\"Parse Dexscreener pair data into TokenInfo\"\"\"\n",
    "        try:\n",
    "            return TokenInfo(\n",
    "                address=pair_data.get('baseToken', {}).get('address', ''),\n",
    "                name=pair_data.get('baseToken', {}).get('name', ''),\n",
    "                symbol=pair_data.get('baseToken', {}).get('symbol', ''),\n",
    "                price_usd=float(pair_data.get('priceUsd', 0)),\n",
    "                price_change_24h=float(pair_data.get('priceChange', {}).get('h24', 0)),\n",
    "                volume_24h=float(pair_data.get('volume', {}).get('h24', 0)),\n",
    "                liquidity=float(pair_data.get('liquidity', {}).get('usd', 0)),\n",
    "                fdv=float(pair_data.get('fdv', 0)),\n",
    "                market_cap=float(pair_data.get('marketCap', 0)),\n",
    "                pair_created_at=datetime.fromtimestamp(pair_data.get('pairCreatedAt', 0) / 1000),\n",
    "                dex_id=pair_data.get('dexId', ''),\n",
    "                chain_id=pair_data.get('chainId', ''),\n",
    "                pair_address=pair_data.get('pairAddress', '')\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error parsing token info: {e}\")\n",
    "            return None\n",
    "\n",
    "\n",
    "class TwitterTrendAnalyzer:\n",
    "    \"\"\"Twitter/X trend analyzer for memecoin detection\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str = None, api_secret: str = None, \n",
    "                 bearer_token: str = None, access_token: str = None, \n",
    "                 access_token_secret: str = None):\n",
    "        self.api_key = api_key\n",
    "        self.api_secret = api_secret\n",
    "        self.bearer_token = bearer_token\n",
    "        self.access_token = access_token\n",
    "        self.access_token_secret = access_token_secret\n",
    "        self.client = None\n",
    "        self._initialize_client()\n",
    "        \n",
    "    def _initialize_client(self):\n",
    "        \"\"\"Initialize Twitter API client\"\"\"\n",
    "        if not TWITTER_AVAILABLE or not TWITTER_LIB:\n",
    "            logger.warning(\"Twitter libraries not available\")\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            if TWITTER_LIB == 'tweepy':\n",
    "                import tweepy\n",
    "                if self.bearer_token:\n",
    "                    self.client = tweepy.Client(bearer_token=self.bearer_token)\n",
    "                elif self.api_key and self.api_secret:\n",
    "                    auth = tweepy.OAuthHandler(self.api_key, self.api_secret)\n",
    "                    if self.access_token and self.access_token_secret:\n",
    "                        auth.set_access_token(self.access_token, self.access_token_secret)\n",
    "                    self.client = tweepy.API(auth)\n",
    "            else:\n",
    "                # Using twitter-api-v2\n",
    "                from twitter_api_v2 import TwitterApi\n",
    "                self.client = TwitterApi(bearer_token=self.bearer_token)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to initialize Twitter client: {e}\")\n",
    "            self.client = None\n",
    "    \n",
    "    def search_tweets(self, query: str, max_results: int = 100) -> List[Dict]:\n",
    "        \"\"\"Search for tweets matching query\"\"\"\n",
    "        if not self.client:\n",
    "            return []\n",
    "            \n",
    "        try:\n",
    "            if TWITTER_LIB == 'tweepy':\n",
    "                tweets = self.client.search_recent_tweets(\n",
    "                    query=query,\n",
    "                    max_results=min(max_results, 100),\n",
    "                    tweet_fields=['created_at', 'public_metrics', 'author_id']\n",
    "                )\n",
    "                if tweets.data:\n",
    "                    return [tweet.data for tweet in tweets.data]\n",
    "            else:\n",
    "                # Using twitter-api-v2\n",
    "                response = self.client.search_recent_tweets(\n",
    "                    query=query,\n",
    "                    max_results=max_results\n",
    "                )\n",
    "                if response.data:\n",
    "                    return response.data\n",
    "            return []\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error searching tweets: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def analyze_token_trend(self, token_symbol: str, token_address: str) -> TwitterTrend:\n",
    "        \"\"\"Analyze Twitter trends for a specific token\"\"\"\n",
    "        if not self.client:\n",
    "            return TwitterTrend(\n",
    "                token_address=token_address,\n",
    "                mentions_count=0,\n",
    "                engagement_rate=0.0,\n",
    "                sentiment_score=0.0,\n",
    "                trending_keywords=[],\n",
    "                last_updated=datetime.now()\n",
    "            )\n",
    "        \n",
    "        # Search for token mentions\n",
    "        queries = [\n",
    "            f\"${token_symbol}\",\n",
    "            f\"#{token_symbol}\",\n",
    "            token_symbol,\n",
    "            token_address[:8]  # Partial address\n",
    "        ]\n",
    "        \n",
    "        total_mentions = 0\n",
    "        total_engagement = 0\n",
    "        keywords = []\n",
    "        \n",
    "        for query in queries:\n",
    "            try:\n",
    "                tweets = self.search_tweets(query, max_results=50)\n",
    "                total_mentions += len(tweets)\n",
    "                \n",
    "                for tweet in tweets:\n",
    "                    # Calculate engagement (likes + retweets + replies)\n",
    "                    if 'public_metrics' in tweet:\n",
    "                        metrics = tweet['public_metrics']\n",
    "                        engagement = metrics.get('like_count', 0) + \\\n",
    "                                    metrics.get('retweet_count', 0) + \\\n",
    "                                    metrics.get('reply_count', 0)\n",
    "                        total_engagement += engagement\n",
    "                    \n",
    "                    # Extract keywords\n",
    "                    if 'text' in tweet:\n",
    "                        text = tweet['text'].lower()\n",
    "                        keywords.extend([w for w in text.split() if len(w) > 3])\n",
    "            except Exception as e:\n",
    "                logger.debug(f\"Error analyzing query {query}: {e}\")\n",
    "        \n",
    "        # Calculate sentiment (simplified - can be enhanced with NLP)\n",
    "        sentiment_score = 0.0  # Placeholder - implement sentiment analysis\n",
    "        \n",
    "        # Calculate engagement rate\n",
    "        engagement_rate = total_engagement / max(total_mentions, 1)\n",
    "        \n",
    "        # Get trending keywords\n",
    "        from collections import Counter\n",
    "        keyword_counts = Counter(keywords)\n",
    "        trending_keywords = [word for word, count in keyword_counts.most_common(10)]\n",
    "        \n",
    "        twitter_mentions.labels(token=token_symbol).inc(total_mentions)\n",
    "        \n",
    "        return TwitterTrend(\n",
    "            token_address=token_address,\n",
    "            mentions_count=total_mentions,\n",
    "            engagement_rate=engagement_rate,\n",
    "            sentiment_score=sentiment_score,\n",
    "            trending_keywords=trending_keywords,\n",
    "            last_updated=datetime.now()\n",
    "        )\n",
    "\n",
    "\n",
    "class SolanaTrader:\n",
    "    \"\"\"Solana blockchain trader using Jupiter DEX aggregator\"\"\"\n",
    "    \n",
    "    def __init__(self, private_key: str, rpc_url: str = \"https://api.mainnet-beta.solana.com\"):\n",
    "        if not SOLANA_AVAILABLE:\n",
    "            raise ImportError(\"Solana libraries not available\")\n",
    "        \n",
    "        self.private_key = private_key\n",
    "        self.rpc_url = rpc_url\n",
    "        self.keypair = None\n",
    "        self.client = None\n",
    "        self._initialize()\n",
    "        \n",
    "    def _initialize(self):\n",
    "        \"\"\"Initialize Solana client and keypair\"\"\"\n",
    "        try:\n",
    "            # Load keypair from private key\n",
    "            if isinstance(self.private_key, str):\n",
    "                # Assume base58 encoded private key\n",
    "                private_key_bytes = base58.b58decode(self.private_key)\n",
    "                self.keypair = Keypair.from_bytes(private_key_bytes)\n",
    "            else:\n",
    "                self.keypair = Keypair.from_bytes(self.private_key)\n",
    "            \n",
    "            # Initialize async client\n",
    "            self.client = AsyncClient(self.rpc_url)\n",
    "            logger.info(f\"Solana trader initialized. Public key: {self.keypair.pubkey()}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to initialize Solana trader: {e}\")\n",
    "            raise\n",
    "    \n",
    "    async def get_balance(self) -> float:\n",
    "        \"\"\"Get SOL balance\"\"\"\n",
    "        try:\n",
    "            response = await self.client.get_balance(self.keypair.pubkey())\n",
    "            return response.value / 1e9  # Convert lamports to SOL\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error getting balance: {e}\")\n",
    "            return 0.0\n",
    "    \n",
    "    async def get_token_balance(self, token_address: str) -> float:\n",
    "        \"\"\"Get SPL token balance\"\"\"\n",
    "        try:\n",
    "            token_pubkey = Pubkey.from_string(token_address)\n",
    "            # This requires additional implementation for SPL token accounts\n",
    "            # Simplified for now\n",
    "            return 0.0\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error getting token balance: {e}\")\n",
    "            return 0.0\n",
    "    \n",
    "    async def swap_tokens(self, input_mint: str, output_mint: str, \n",
    "                         amount: float, slippage_bps: int = 100) -> Optional[str]:\n",
    "        \"\"\"Swap tokens using Jupiter DEX aggregator\"\"\"\n",
    "        if not JUPITER_AVAILABLE:\n",
    "            logger.error(\"Jupiter SDK not available\")\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            # Jupiter API integration\n",
    "            jupiter_url = \"https://quote-api.jup.ag/v6/quote\"\n",
    "            \n",
    "            # Get quote\n",
    "            quote_params = {\n",
    "                \"inputMint\": input_mint,\n",
    "                \"outputMint\": output_mint,\n",
    "                \"amount\": int(amount * 1e9),  # Convert SOL to lamports\n",
    "                \"slippageBps\": slippage_bps\n",
    "            }\n",
    "            \n",
    "            response = requests.get(jupiter_url, params=quote_params, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            quote = response.json()\n",
    "            \n",
    "            if 'error' in quote:\n",
    "                logger.error(f\"Jupiter quote error: {quote['error']}\")\n",
    "                return None\n",
    "            \n",
    "            # Execute swap (simplified - full implementation requires transaction building)\n",
    "            logger.info(f\"Quote received: {quote.get('outAmount', 0)} output tokens\")\n",
    "            \n",
    "            # TODO: Build and send transaction\n",
    "            # This requires full Jupiter swap integration\n",
    "            \n",
    "            return None  # Return transaction signature when implemented\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error swapping tokens: {e}\")\n",
    "            return None\n",
    "    \n",
    "    async def snipe_token(self, token_address: str, sol_amount: float, \n",
    "                         slippage_bps: int = 500) -> Optional[str]:\n",
    "        \"\"\"Snipe a token (buy immediately after listing)\"\"\"\n",
    "        try:\n",
    "            # SOL mint address\n",
    "            sol_mint = \"So11111111111111111111111111111111111111112\"\n",
    "            \n",
    "            # Execute swap\n",
    "            tx_signature = await self.swap_tokens(\n",
    "                input_mint=sol_mint,\n",
    "                output_mint=token_address,\n",
    "                amount=sol_amount,\n",
    "                slippage_bps=slippage_bps\n",
    "            )\n",
    "            \n",
    "            if tx_signature:\n",
    "                logger.info(f\"Successfully sniped {token_address}. TX: {tx_signature}\")\n",
    "                snipe_success.labels(token=token_address[:8]).inc()\n",
    "                return tx_signature\n",
    "            else:\n",
    "                logger.error(f\"Failed to snipe {token_address}\")\n",
    "                snipe_failures.labels(reason='swap_failed').inc()\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error sniping token: {e}\")\n",
    "            snipe_failures.labels(reason='exception').inc()\n",
    "            return None\n",
    "\n",
    "\n",
    "class MemecoinSniperBot:\n",
    "    \"\"\"Main bot for memecoin sniping based on Dexscreener and Twitter trends\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Dict[str, Any]):\n",
    "        self.config = config\n",
    "        \n",
    "        # Initialize components\n",
    "        self.dexscreener = DexscreenerAPI()\n",
    "        self.twitter = TwitterTrendAnalyzer(\n",
    "            api_key=config.get('twitter_api_key'),\n",
    "            api_secret=config.get('twitter_api_secret'),\n",
    "            bearer_token=config.get('twitter_bearer_token'),\n",
    "            access_token=config.get('twitter_access_token'),\n",
    "            access_token_secret=config.get('twitter_access_token_secret')\n",
    "        )\n",
    "        \n",
    "        if config.get('solana_private_key'):\n",
    "            self.trader = SolanaTrader(\n",
    "                private_key=config['solana_private_key'],\n",
    "                rpc_url=config.get('solana_rpc_url', 'https://api.mainnet-beta.solana.com')\n",
    "            )\n",
    "        else:\n",
    "            self.trader = None\n",
    "            logger.warning(\"No Solana private key provided - trading disabled\")\n",
    "        \n",
    "        # Trading parameters\n",
    "        self.min_liquidity = config.get('min_liquidity', 50000)  # USD\n",
    "        self.max_market_cap = config.get('max_market_cap', 10000000)  # USD\n",
    "        self.min_volume_24h = config.get('min_volume_24h', 10000)  # USD\n",
    "        self.max_age_hours = config.get('max_age_hours', 24)  # Token age\n",
    "        self.min_twitter_mentions = config.get('min_twitter_mentions', 10)\n",
    "        self.snipe_amount_sol = config.get('snipe_amount_sol', 0.1)  # SOL per snipe\n",
    "        self.max_positions = config.get('max_positions', 5)\n",
    "        self.slippage_bps = config.get('slippage_bps', 500)  # 5% slippage\n",
    "        \n",
    "        # State\n",
    "        self.active_positions = {}  # token_address -> position info\n",
    "        self.scanned_tokens = set()\n",
    "        \n",
    "        logger.info(\"Memecoin Sniper Bot initialized\")\n",
    "    \n",
    "    def calculate_token_score(self, token: TokenInfo, twitter_trend: TwitterTrend) -> float:\n",
    "        \"\"\"Calculate score for a token based on multiple factors\"\"\"\n",
    "        score = 0.0\n",
    "        \n",
    "        # Liquidity score (higher is better, but not too high)\n",
    "        if token.liquidity >= self.min_liquidity:\n",
    "            liquidity_score = min(token.liquidity / 1000000, 1.0) * 20\n",
    "            score += liquidity_score\n",
    "        \n",
    "        # Volume score\n",
    "        if token.volume_24h >= self.min_volume_24h:\n",
    "            volume_score = min(token.volume_24h / 1000000, 1.0) * 25\n",
    "            score += volume_score\n",
    "        \n",
    "        # Price change score (momentum)\n",
    "        if token.price_change_24h > 0:\n",
    "            price_score = min(token.price_change_24h / 100, 1.0) * 20\n",
    "            score += price_score\n",
    "        \n",
    "        # Market cap score (prefer lower for memecoins)\n",
    "        if 0 < token.market_cap <= self.max_market_cap:\n",
    "            market_cap_score = (1 - token.market_cap / self.max_market_cap) * 15\n",
    "            score += market_cap_score\n",
    "        \n",
    "        # Age score (newer is better)\n",
    "        age_hours = (datetime.now() - token.pair_created_at).total_seconds() / 3600\n",
    "        if age_hours <= self.max_age_hours:\n",
    "            age_score = (1 - age_hours / self.max_age_hours) * 10\n",
    "            score += age_score\n",
    "        \n",
    "        # Twitter trend score\n",
    "        if twitter_trend.mentions_count >= self.min_twitter_mentions:\n",
    "            mention_score = min(twitter_trend.mentions_count / 100, 1.0) * 5\n",
    "            score += mention_score\n",
    "        \n",
    "        if twitter_trend.engagement_rate > 0:\n",
    "            engagement_score = min(twitter_trend.engagement_rate / 100, 1.0) * 5\n",
    "            score += engagement_score\n",
    "        \n",
    "        token.score = score\n",
    "        token_score.labels(token_address=token.address[:8]).set(score)\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    def filter_tokens(self, tokens: List[TokenInfo]) -> List[TokenInfo]:\n",
    "        \"\"\"Filter tokens based on criteria\"\"\"\n",
    "        filtered = []\n",
    "        \n",
    "        for token in tokens:\n",
    "            # Basic filters\n",
    "            if token.liquidity < self.min_liquidity:\n",
    "                continue\n",
    "            if token.market_cap > self.max_market_cap:\n",
    "                continue\n",
    "            if token.volume_24h < self.min_volume_24h:\n",
    "                continue\n",
    "            \n",
    "            # Age filter\n",
    "            age_hours = (datetime.now() - token.pair_created_at).total_seconds() / 3600\n",
    "            if age_hours > self.max_age_hours:\n",
    "                continue\n",
    "            \n",
    "            # Already scanned\n",
    "            if token.address in self.scanned_tokens:\n",
    "                continue\n",
    "            \n",
    "            filtered.append(token)\n",
    "        \n",
    "        return filtered\n",
    "    \n",
    "    async def scan_and_score_tokens(self, limit: int = 50) -> List[Tuple[TokenInfo, TwitterTrend, float]]:\n",
    "        \"\"\"Scan Dexscreener for tokens and score them\"\"\"\n",
    "        logger.info(f\"Scanning Dexscreener for top {limit} tokens...\")\n",
    "        \n",
    "        # Get tokens from Dexscreener\n",
    "        pairs_data = self.dexscreener.get_tokens_by_chain(\"solana\", limit=limit)\n",
    "        \n",
    "        # Parse token info\n",
    "        tokens = []\n",
    "        for pair_data in pairs_data:\n",
    "            token = self.dexscreener.parse_token_info(pair_data)\n",
    "            if token:\n",
    "                tokens.append(token)\n",
    "        \n",
    "        # Filter tokens\n",
    "        filtered_tokens = self.filter_tokens(tokens)\n",
    "        logger.info(f\"Found {len(filtered_tokens)} tokens matching criteria\")\n",
    "        \n",
    "        # Score tokens with Twitter analysis\n",
    "        scored_tokens = []\n",
    "        for token in filtered_tokens:\n",
    "            try:\n",
    "                # Analyze Twitter trends\n",
    "                twitter_trend = self.twitter.analyze_token_trend(token.symbol, token.address)\n",
    "                \n",
    "                # Calculate score\n",
    "                score = self.calculate_token_score(token, twitter_trend)\n",
    "                \n",
    "                scored_tokens.append((token, twitter_trend, score))\n",
    "                self.scanned_tokens.add(token.address)\n",
    "                \n",
    "                logger.debug(f\"Token {token.symbol} ({token.address[:8]}): Score={score:.2f}, \"\n",
    "                           f\"Liquidity=${token.liquidity:,.0f}, Mentions={twitter_trend.mentions_count}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing token {token.address}: {e}\")\n",
    "        \n",
    "        # Sort by score\n",
    "        scored_tokens.sort(key=lambda x: x[2], reverse=True)\n",
    "        \n",
    "        return scored_tokens\n",
    "    \n",
    "    async def execute_snipe(self, token: TokenInfo) -> bool:\n",
    "        \"\"\"Execute a snipe on a token\"\"\"\n",
    "        if not self.trader:\n",
    "            logger.error(\"Trader not initialized - cannot execute snipe\")\n",
    "            return False\n",
    "        \n",
    "        if len(self.active_positions) >= self.max_positions:\n",
    "            logger.warning(f\"Max positions reached ({self.max_positions})\")\n",
    "            return False\n",
    "        \n",
    "        # Check balance\n",
    "        balance = await self.trader.get_balance()\n",
    "        if balance < self.snipe_amount_sol:\n",
    "            logger.warning(f\"Insufficient balance: {balance} SOL < {self.snipe_amount_sol} SOL\")\n",
    "            return False\n",
    "        \n",
    "        logger.info(f\"Executing snipe on {token.symbol} ({token.address})\")\n",
    "        snipe_attempts.labels(status='attempting').inc()\n",
    "        \n",
    "        # Execute snipe\n",
    "        tx_signature = await self.trader.snipe_token(\n",
    "            token_address=token.address,\n",
    "            sol_amount=self.snipe_amount_sol,\n",
    "            slippage_bps=self.slippage_bps\n",
    "        )\n",
    "        \n",
    "        if tx_signature:\n",
    "            # Record position\n",
    "            self.active_positions[token.address] = {\n",
    "                'token': token,\n",
    "                'entry_time': datetime.now(),\n",
    "                'entry_price': token.price_usd,\n",
    "                'amount_sol': self.snipe_amount_sol,\n",
    "                'tx_signature': tx_signature\n",
    "            }\n",
    "            active_positions.set(len(self.active_positions))\n",
    "            logger.info(f\"Snipe successful! TX: {tx_signature}\")\n",
    "            return True\n",
    "        else:\n",
    "            logger.error(f\"Snipe failed for {token.symbol}\")\n",
    "            return False\n",
    "    \n",
    "    async def run_scan_cycle(self):\n",
    "        \"\"\"Run one scan cycle\"\"\"\n",
    "        try:\n",
    "            # Scan and score tokens\n",
    "            scored_tokens = await self.scan_and_score_tokens(limit=50)\n",
    "            \n",
    "            if not scored_tokens:\n",
    "                logger.info(\"No tokens found matching criteria\")\n",
    "                return\n",
    "            \n",
    "            # Log top tokens\n",
    "            logger.info(f\"\\n=== Top Tokens ===\")\n",
    "            for i, (token, twitter_trend, score) in enumerate(scored_tokens[:10], 1):\n",
    "                logger.info(f\"{i}. {token.symbol} ({token.address[:8]}) - Score: {score:.2f}\")\n",
    "                logger.info(f\"   Price: ${token.price_usd:.8f}, Liquidity: ${token.liquidity:,.0f}\")\n",
    "                logger.info(f\"   Twitter: {twitter_trend.mentions_count} mentions, \"\n",
    "                          f\"Engagement: {twitter_trend.engagement_rate:.2f}\")\n",
    "            \n",
    "            # Execute snipes on top tokens\n",
    "            for token, twitter_trend, score in scored_tokens[:5]:  # Top 5\n",
    "                if len(self.active_positions) >= self.max_positions:\n",
    "                    break\n",
    "                \n",
    "                # Only snipe if score is above threshold\n",
    "                if score >= self.config.get('min_score_threshold', 50.0):\n",
    "                    await self.execute_snipe(token)\n",
    "                    await asyncio.sleep(2)  # Rate limiting\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in scan cycle: {e}\")\n",
    "            import traceback\n",
    "            logger.debug(traceback.format_exc())\n",
    "    \n",
    "    async def run(self, scan_interval_seconds: int = 60):\n",
    "        \"\"\"Run the bot continuously\"\"\"\n",
    "        logger.info(f\"Starting bot with {scan_interval_seconds}s scan interval\")\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                await self.run_scan_cycle()\n",
    "                logger.info(f\"Waiting {scan_interval_seconds}s until next scan...\")\n",
    "                await asyncio.sleep(scan_interval_seconds)\n",
    "            except KeyboardInterrupt:\n",
    "                logger.info(\"Bot stopped by user\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error in main loop: {e}\")\n",
    "                await asyncio.sleep(scan_interval_seconds)\n",
    "\n",
    "\n",
    "# Example usage and configuration\n",
    "def main():\n",
    "    \"\"\"Main entry point\"\"\"\n",
    "    # Load configuration from environment or config file\n",
    "    config = {\n",
    "        # Solana configuration\n",
    "        'solana_private_key': os.getenv('SOLANA_PRIVATE_KEY', ''),\n",
    "        'solana_rpc_url': os.getenv('SOLANA_RPC_URL', 'https://api.mainnet-beta.solana.com'),\n",
    "        \n",
    "        # Twitter configuration\n",
    "        'twitter_bearer_token': os.getenv('TWITTER_BEARER_TOKEN', ''),\n",
    "        'twitter_api_key': os.getenv('TWITTER_API_KEY', ''),\n",
    "        'twitter_api_secret': os.getenv('TWITTER_API_SECRET', ''),\n",
    "        'twitter_access_token': os.getenv('TWITTER_ACCESS_TOKEN', ''),\n",
    "        'twitter_access_token_secret': os.getenv('TWITTER_ACCESS_TOKEN_SECRET', ''),\n",
    "        \n",
    "        # Trading parameters\n",
    "        'min_liquidity': float(os.getenv('MIN_LIQUIDITY', '50000')),\n",
    "        'max_market_cap': float(os.getenv('MAX_MARKET_CAP', '10000000')),\n",
    "        'min_volume_24h': float(os.getenv('MIN_VOLUME_24H', '10000')),\n",
    "        'max_age_hours': float(os.getenv('MAX_AGE_HOURS', '24')),\n",
    "        'min_twitter_mentions': int(os.getenv('MIN_TWITTER_MENTIONS', '10')),\n",
    "        'snipe_amount_sol': float(os.getenv('SNIPE_AMOUNT_SOL', '0.1')),\n",
    "        'max_positions': int(os.getenv('MAX_POSITIONS', '5')),\n",
    "        'slippage_bps': int(os.getenv('SLIPPAGE_BPS', '500')),\n",
    "        'min_score_threshold': float(os.getenv('MIN_SCORE_THRESHOLD', '50.0')),\n",
    "    }\n",
    "    \n",
    "    # Start Prometheus metrics server\n",
    "    try:\n",
    "        start_http_server(8000)\n",
    "        logger.info(\"Prometheus metrics server started on port 8000\")\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Could not start metrics server: {e}\")\n",
    "    \n",
    "    # Initialize and run bot\n",
    "    bot = MemecoinSniperBot(config)\n",
    "    \n",
    "    # Run bot\n",
    "    scan_interval = int(os.getenv('SCAN_INTERVAL_SECONDS', '60'))\n",
    "    asyncio.run(bot.run(scan_interval_seconds=scan_interval))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
